{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc34a3d-5add-4dcd-bb68-833e2583644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow_addons\n",
    "! pip install nfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa08d14-0e73-461b-a999-8fa5fbf4a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 17:19:42.152935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-04 17:19:42.293455: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-04 17:19:42.865621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/g16/bsd:/usr/local/g16:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64::/usr/local/gv/lib\n",
      "2025-03-04 17:19:42.865720: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/g16/bsd:/usr/local/g16:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64::/usr/local/gv/lib\n",
      "2025-03-04 17:19:42.865727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-03-04 17:19:43.515927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-03-04 17:19:43.520559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/g16/bsd:/usr/local/g16:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64::/usr/local/gv/lib\n",
      "2025-03-04 17:19:43.521313: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac1b06b-2375-48f2-9009-16461116722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhs/.conda/envs/2D_GNNs/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nfp\n",
    "from preprocess_inputs_cfc import preprocessor\n",
    "preprocessor.from_json('model_3_tfrecords_multi_halo_cfc/preprocessor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b2510e-9c1a-4cd9-b514-01b026af78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 17:19:45.172002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class Slice(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        num_bonds = input_shape[1] / 2\n",
    "        output = tf.slice(inputs, [0, 0, 0], [-1, num_bonds, -1])\n",
    "        output.set_shape(self.compute_output_shape(inputs.shape))\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [input_shape[0], None, input_shape[2]]\n",
    "    \n",
    "custom_objects = {**nfp.custom_objects,'Slice':Slice}\n",
    "\n",
    "model = tf.keras.models.load_model('model_3_multi_halo_cfc/best_model.hdf5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3746c7dd-c9df-49ce-85ac-568841b6d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CN_shap_250213.csv\")\n",
    "molecule_smiles=data.Canonical_SMILES.unique()\n",
    "\n",
    "test = np.array(molecule_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7207347f-ebf2-4d98-917d-6b1203272803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(smiles):\n",
    "    input_dict = preprocessor(smiles)\n",
    "    input_dict['n_atom'] = len(input_dict['atom'] )\n",
    "    input_dict['n_bond'] = len(input_dict['bond'] )\n",
    "    return input_dict\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        lambda:  (iter(get_data(smiles) for smiles in test)), \n",
    "        output_signature= { **preprocessor.output_signature,'n_atom': tf.TensorSpec(shape=(), dtype=tf.int32, name=None),\\\n",
    "        'n_bond': tf.TensorSpec(shape=(), dtype=tf.int32, name=None) })\n",
    "    .padded_batch(batch_size=1000, padding_values={**preprocessor.padding_values,'n_atom': tf.constant(0, dtype=\"int32\"),\\\n",
    "        'n_bond': tf.constant(0, dtype=\"int32\")})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2c3630-ffda-427f-b7b4-5ffe32859cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhs/.conda/envs/2D_GNNs/lib/python3.8/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['n_atom', 'n_bond'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "predicted_bdes = model.predict(test_dataset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc1e050-e26b-4df6-b591-d3e27d12aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_bdes.reshape(-1, 2), columns=['pred_bde','pred_bdfe'])\n",
    "df.index = test[np.repeat(np.arange(predicted_bdes.shape[0]), predicted_bdes.shape[1])]\n",
    "\n",
    "def func(x):\n",
    "    x['bond_index'] = range(0, predicted_bdes.shape[1])\n",
    "    return x\n",
    "\n",
    "pred_bdes = df.reset_index().rename(columns={'index': 'molecule'})\n",
    "pred_bdes = pred_bdes.groupby('molecule',group_keys=False).apply(func)\n",
    "pred_bdes = pred_bdes[(pred_bdes['pred_bde'] != 0.000000) &(pred_bdes['pred_bde'] != 0.000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b634b2-0ab3-4044-b873-cb1264e25efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bdes.to_csv('full_bde.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6893e4f5-f66a-4c64-9cb4-313a934d1a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of True values in 'filtered_bde_1_smallest.csv': 291\n",
      "Results saved to rank_match_1.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_2_smallest.csv': 378\n",
      "Results saved to rank_match_2.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_3_smallest.csv': 444\n",
      "Results saved to rank_match_3.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_4_smallest.csv': 490\n",
      "Results saved to rank_match_4.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_5_smallest.csv': 516\n",
      "Results saved to rank_match_5.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "df = pd.read_csv('full_bde.csv')\n",
    "dd = pd.read_csv('CN_shap_250213.csv')\n",
    "\n",
    "def get_atom_indices(smiles, bond_index):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    if bond_index >= mol.GetNumBonds():\n",
    "        return None, None \n",
    "    bond = mol.GetBondWithIdx(bond_index)\n",
    "    atom1 = bond.GetBeginAtomIdx()\n",
    "    atom2 = bond.GetEndAtomIdx()\n",
    "    return atom1, atom2\n",
    "\n",
    "def convert_to_list(value):\n",
    "    try:\n",
    "        return [float(x) for x in value.strip('[]').split()] \n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def get_max_min_indices(atomwise_list):\n",
    "    if not atomwise_list:\n",
    "        return set()\n",
    "    max_indices = set(np.where(atomwise_list == np.max(atomwise_list))[0])\n",
    "    min_indices = set(np.where(atomwise_list == np.min(atomwise_list))[0])\n",
    "    return max_indices.union(min_indices)\n",
    "\n",
    "dd['atomwise_shap'] = dd['atomwise_shap'].apply(convert_to_list)\n",
    "dd['max_min_indices'] = dd['atomwise_shap'].apply(get_max_min_indices)\n",
    "\n",
    "bde_results = {}\n",
    "for rank in range(1, 6):\n",
    "    bde_results[rank] = []\n",
    "\n",
    "for smiles, group in df.groupby('molecule'):\n",
    "    sorted_group = group.sort_values('pred_bde')\n",
    "    bde_thresholds = sorted_group['pred_bde'].unique()[:5]\n",
    "    selected_group = sorted_group[sorted_group['pred_bde'].isin(bde_thresholds)]\n",
    "    \n",
    "    for rank in range(len(bde_thresholds)):\n",
    "        for _, row in selected_group[selected_group['pred_bde'] <= bde_thresholds[rank]].iterrows():\n",
    "            bond_index = int(row['bond_index'])\n",
    "            atom_indices = get_atom_indices(smiles, bond_index)\n",
    "            if atom_indices[0] is not None:\n",
    "                bde_results[rank + 1].append({\n",
    "                    'molecule': smiles,\n",
    "                    'atom_index_1': atom_indices[0],\n",
    "                    'atom_index_2': atom_indices[1],\n",
    "                    'bond_index': bond_index,\n",
    "                    'pred_bde': row['pred_bde']\n",
    "                })\n",
    "\n",
    "for rank in range(1, 6):\n",
    "    result_df = pd.DataFrame(bde_results[rank])\n",
    "    result_df.to_csv(f'filtered_bde_{rank}_smallest.csv', index=False)\n",
    "\n",
    "input_files = [f'filtered_bde_{rank}_smallest.csv' for rank in range(1, 6)]\n",
    "\n",
    "for i, input_file in enumerate(input_files, start=1):\n",
    "    result_df = pd.read_csv(input_file)\n",
    "    \n",
    "    merged_df = pd.merge(result_df, dd, left_on='molecule', right_on='Canonical_SMILES', how='left')\n",
    "    merged_df = merged_df.drop_duplicates(subset=['molecule', 'bond_index', 'atom_index_1', 'atom_index_2'])\n",
    "    \n",
    "    smiles_atom_index_map = merged_df.groupby('molecule').apply(\n",
    "        lambda group: set(group['atom_index_1']).union(set(group['atom_index_2']))\n",
    "    ).to_dict()\n",
    "\n",
    "    def check_match(smiles, max_min_indices):\n",
    "        if smiles not in smiles_atom_index_map:\n",
    "            return False\n",
    "        atom_index_set = smiles_atom_index_map[smiles]\n",
    "        return not max_min_indices.isdisjoint(atom_index_set)\n",
    "\n",
    "    merged_df['match'] = merged_df.apply(lambda row: check_match(row['molecule'], row['max_min_indices']), axis=1)\n",
    "\n",
    "    final_result = merged_df[['molecule', 'match']].drop_duplicates()\n",
    "    true_count = final_result['match'].sum()\n",
    "    print(f\"Total number of True values in '{input_file}': {true_count}\")\n",
    "    output_file = f\"rank_match_{i}.csv\"\n",
    "    final_result.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e403b6-c20d-4d18-8b3c-19bf3ba92914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of True values in 'filtered_bde_plus_0.csv': 291\n",
      "Results saved to energy_match_1.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_plus_2.csv': 369\n",
      "Results saved to energy_match_2.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_plus_4.csv': 444\n",
      "Results saved to energy_match_3.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_plus_6.csv': 456\n",
      "Results saved to energy_match_4.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_plus_8.csv': 470\n",
      "Results saved to energy_match_5.csv\n",
      "\n",
      "Total number of True values in 'filtered_bde_plus_10.csv': 479\n",
      "Results saved to energy_match_6.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "df = pd.read_csv('full_bde.csv')\n",
    "dd = pd.read_csv('CN_shap_250213.csv')\n",
    "\n",
    "def get_atom_indices(smiles, bond_index):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    if bond_index >= mol.GetNumBonds():\n",
    "        return None, None \n",
    "    bond = mol.GetBondWithIdx(bond_index)\n",
    "    atom1 = bond.GetBeginAtomIdx()\n",
    "    atom2 = bond.GetEndAtomIdx()\n",
    "    return atom1, atom2\n",
    "\n",
    "def convert_to_list(value):\n",
    "    try:\n",
    "        return [float(x) for x in value.strip('[]').split()] \n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def get_max_min_indices(atomwise_list):\n",
    "    if not atomwise_list:\n",
    "        return set()\n",
    "    max_indices = set(np.where(atomwise_list == np.max(atomwise_list))[0])\n",
    "    min_indices = set(np.where(atomwise_list == np.min(atomwise_list))[0])\n",
    "    return max_indices.union(min_indices)\n",
    "\n",
    "dd['atomwise_shap'] = dd['atomwise_shap'].apply(convert_to_list)\n",
    "dd['max_min_indices'] = dd['atomwise_shap'].apply(get_max_min_indices)\n",
    "\n",
    "bde_results = {\"plus_0\": [], \"plus_2\": [], \"plus_4\": [], \"plus_6\": [], \"plus_8\": [], \"plus_10\": []}\n",
    "\n",
    "for smiles, group in df.groupby('molecule'):\n",
    "    sorted_group = group.sort_values('pred_bde')\n",
    "    weakest_bde = sorted_group['pred_bde'].min()\n",
    "    \n",
    "    bde_ranges = {\n",
    "        \"plus_0\": weakest_bde,\n",
    "        \"plus_2\": weakest_bde + 2,\n",
    "        \"plus_4\": weakest_bde + 4,\n",
    "        \"plus_6\": weakest_bde + 6,\n",
    "        \"plus_8\": weakest_bde + 8,\n",
    "        \"plus_10\": weakest_bde + 10,\n",
    "    }\n",
    "    \n",
    "    for key, bde_limit in bde_ranges.items():\n",
    "        selected_group = sorted_group[sorted_group['pred_bde'] <= bde_limit]\n",
    "        for _, row in selected_group.iterrows():\n",
    "            bond_index = int(row['bond_index'])\n",
    "            atom_indices = get_atom_indices(smiles, bond_index)\n",
    "            if atom_indices[0] is not None:\n",
    "                bde_results[key].append({\n",
    "                    'molecule': smiles,\n",
    "                    'atom_index_1': atom_indices[0],\n",
    "                    'atom_index_2': atom_indices[1],\n",
    "                    'bond_index': bond_index,\n",
    "                    'pred_bde': row['pred_bde']\n",
    "                })\n",
    "\n",
    "for key in bde_results:\n",
    "    result_df = pd.DataFrame(bde_results[key])\n",
    "    result_df.to_csv(f'filtered_bde_{key}.csv', index=False)\n",
    "\n",
    "input_files = [f'filtered_bde_{key}.csv' for key in bde_results]\n",
    "\n",
    "for i, input_file in enumerate(input_files, start=1):\n",
    "    result_df = pd.read_csv(input_file)\n",
    "    \n",
    "    merged_df = pd.merge(result_df, dd, left_on='molecule', right_on='Canonical_SMILES', how='left')\n",
    "    merged_df = merged_df.drop_duplicates(subset=['molecule', 'bond_index', 'atom_index_1', 'atom_index_2'])\n",
    "    \n",
    "    smiles_atom_index_map = merged_df.groupby('molecule').apply(\n",
    "        lambda group: set(group['atom_index_1']).union(set(group['atom_index_2']))\n",
    "    ).to_dict()\n",
    "\n",
    "    def check_match(smiles, max_min_indices):\n",
    "        if smiles not in smiles_atom_index_map:\n",
    "            return False\n",
    "        atom_index_set = smiles_atom_index_map[smiles]\n",
    "        return not max_min_indices.isdisjoint(atom_index_set)\n",
    "\n",
    "    merged_df['match'] = merged_df.apply(lambda row: check_match(row['molecule'], row['max_min_indices']), axis=1)\n",
    "\n",
    "    final_result = merged_df[['molecule', 'match']].drop_duplicates()\n",
    "    true_count = final_result['match'].sum()\n",
    "    print(f\"Total number of True values in '{input_file}': {true_count}\")\n",
    "    output_file = f\"energy_match_{i}.csv\"\n",
    "    final_result.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b1cc8-f85b-4c22-9393-611877f0d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "file_path = \"rank_match_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def has_ring(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol.HasSubstructMatch(Chem.MolFromSmarts(\"[R]\")) if mol else False\n",
    "\n",
    "df[\"has_ring\"] = df[\"molecule\"].apply(has_ring)\n",
    "\n",
    "group_counts = df.groupby([\"match\", \"has_ring\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d530e4-b1a7-4c53-9772-9fd51d858e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "file_path = \"rank_match_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df[\"match\"] = df[\"match\"].astype(bool)\n",
    "\n",
    "def compute_molecular_features(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return [\n",
    "            Descriptors.MolWt(mol),      \n",
    "            Descriptors.MolLogP(mol),       \n",
    "            Descriptors.TPSA(mol),         \n",
    "            Descriptors.RingCount(mol),     \n",
    "            Descriptors.NumHDonors(mol),       \n",
    "            Descriptors.NumHAcceptors(mol)        \n",
    "        ]\n",
    "    else:\n",
    "        return [None] * 6\n",
    "\n",
    "feature_columns = [\"MolWt\", \"LogP\", \"TPSA\", \"RingCount\", \"NumHDonors\", \"NumHAcceptors\"]\n",
    "\n",
    "df_features = df.copy()\n",
    "df_features[feature_columns] = df_features[\"molecule\"].apply(lambda x: compute_molecular_features(x)).apply(pd.Series)\n",
    "\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "df_true = df_features[df_features[\"match\"] == True]\n",
    "df_false = df_features[df_features[\"match\"] == False]\n",
    "\n",
    "def select_quantile_representatives(df_subset, num_samples=5):\n",
    "    selected_molecules = []\n",
    "    \n",
    "    quantiles = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        quantile_values = df_subset[col].quantile(quantiles).values\n",
    "        \n",
    "        for q_value in quantile_values:\n",
    "            closest_idx = (df_subset[col] - q_value).abs().idxmin()\n",
    "            selected_molecules.append(df_subset.loc[closest_idx])\n",
    "    \n",
    "    selected_df = pd.DataFrame(selected_molecules).drop_duplicates().head(num_samples)\n",
    "    \n",
    "    return selected_df\n",
    "\n",
    "true_representatives = select_quantile_representatives(df_true, 5)\n",
    "false_representatives = select_quantile_representatives(df_false, 5)\n",
    "\n",
    "print(\"=== 대표적인 True 분자 ===\")\n",
    "print(true_representatives[[\"molecule\", *feature_columns]])\n",
    "\n",
    "print(\"\\n=== 대표적인 False 분자 ===\")\n",
    "print(false_representatives[[\"molecule\", *feature_columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c44c55a-2a72-4409-85e9-1760015b1c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical_SMILES</th>\n",
       "      <th>CN</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1=CC=C(C=C1)C(C)C</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1ccccc1OC</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.674105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCOCCCCOCC</td>\n",
       "      <td>97.00</td>\n",
       "      <td>99.701220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCCOCCO</td>\n",
       "      <td>38.30</td>\n",
       "      <td>44.250490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCCOC(=O)C(C)OC</td>\n",
       "      <td>57.50</td>\n",
       "      <td>57.060303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCCC1=CC=C(C=C1)O</td>\n",
       "      <td>8.60</td>\n",
       "      <td>11.207690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCCC=C(CCCC)CCCCCCC</td>\n",
       "      <td>45.00</td>\n",
       "      <td>46.557545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCCCCCCCCCCCCC(=O)OCC</td>\n",
       "      <td>66.90</td>\n",
       "      <td>73.024704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC(C)CCOC(=O)C(C)O</td>\n",
       "      <td>39.72</td>\n",
       "      <td>37.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CCCCCCCC(=O)OCCCC</td>\n",
       "      <td>39.60</td>\n",
       "      <td>40.392070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Canonical_SMILES     CN  predicted\n",
       "0    CC1=CC=C(C=C1)C(C)C   4.00   4.175619\n",
       "1           COc1ccccc1OC   9.80   9.674105\n",
       "2             CCOCCCCOCC  97.00  99.701220\n",
       "3               COCCOCCO  38.30  44.250490\n",
       "4   CCCCCCCCOC(=O)C(C)OC  57.50  57.060303\n",
       "5      CCCC1=CC=C(C=C1)O   8.60  11.207690\n",
       "6    CCCC=C(CCCC)CCCCCCC  45.00  46.557545\n",
       "7  CCCCCCCCCCCCCC(=O)OCC  66.90  73.024704\n",
       "8     CC(C)CCOC(=O)C(C)O  39.72  37.743100\n",
       "9      CCCCCCCC(=O)OCCCC  39.60  40.392070"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"CN_shap_250213.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "target_smiles = [\n",
    "    \"CC1=CC=C(C=C1)C(C)C\",\n",
    "    \"COc1ccccc1OC\",\n",
    "    \"CCOCCCCOCC\",\n",
    "    \"COCCOCCO\",\n",
    "    \"CCCCCCCCOC(=O)C(C)OC\",\n",
    "    \"CCCC1=CC=C(C=C1)O\",\n",
    "    \"CCCC=C(CCCC)CCCCCCC\",\n",
    "    \"CCCCCCCCCCCCCC(=O)OCC\",\n",
    "    \"CC(C)CCOC(=O)C(C)O\",\n",
    "    \"CCCCCCCC(=O)OCCCC\"\n",
    "]\n",
    "\n",
    "filtered_df = df[df[\"Canonical_SMILES\"].isin(target_smiles)][[\"Canonical_SMILES\", \"CN\", \"predicted\"]]\n",
    "\n",
    "filtered_df = filtered_df.set_index(\"Canonical_SMILES\").reindex(target_smiles).reset_index()\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c23d339b-c384-4fa4-a141-483a3133072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>MAE_True</th>\n",
       "      <th>MAE_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rank_match_1.csv</td>\n",
       "      <td>2.248966</td>\n",
       "      <td>2.609559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rank_match_2.csv</td>\n",
       "      <td>2.256251</td>\n",
       "      <td>2.723120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rank_match_3.csv</td>\n",
       "      <td>2.270585</td>\n",
       "      <td>2.866681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rank_match_4.csv</td>\n",
       "      <td>2.367086</td>\n",
       "      <td>2.737389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rank_match_5.csv</td>\n",
       "      <td>2.344781</td>\n",
       "      <td>2.915481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File  MAE_True  MAE_False\n",
       "0  rank_match_1.csv  2.248966   2.609559\n",
       "1  rank_match_2.csv  2.256251   2.723120\n",
       "2  rank_match_3.csv  2.270585   2.866681\n",
       "3  rank_match_4.csv  2.367086   2.737389\n",
       "4  rank_match_5.csv  2.344781   2.915481"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_shap = \"CN_shap_250213.csv\"  \n",
    "rank_files = [f\"rank_match_{i}.csv\" for i in range(1, 6)] \n",
    "\n",
    "df_shap = pd.read_csv(file_path_shap)[[\"Canonical_SMILES\", \"CN\", \"predicted\"]]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_path_rank in rank_files:\n",
    "    \n",
    "    df_rank = pd.read_csv(file_path_rank)[[\"molecule\", \"match\"]]\n",
    "\n",
    "    df_merged = df_rank.merge(df_shap, left_on=\"molecule\", right_on=\"Canonical_SMILES\", how=\"left\")\n",
    "\n",
    "    df_true = df_merged[df_merged[\"match\"] == True]\n",
    "    df_false = df_merged[df_merged[\"match\"] == False]\n",
    "\n",
    "    mae_true = (df_true[\"CN\"] - df_true[\"predicted\"]).abs().mean()\n",
    "    mae_false = (df_false[\"CN\"] - df_false[\"predicted\"]).abs().mean()\n",
    "\n",
    "    results.append({\"File\": file_path_rank, \"MAE_True\": mae_true, \"MAE_False\": mae_false})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cffc6-959d-4946-a53d-1f22e303f00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
